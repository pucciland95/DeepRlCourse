{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7f03d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicco/courses/DeepRlCourse/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from huggingface_sb3 import load_from_hub, package_to_hub\n",
    "from huggingface_hub import (\n",
    "    notebook_login,\n",
    ")  # To log to our Hugging Face account to be able to upload models to the Hub.\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11d579f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicco/courses/DeepRlCourse/venv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action taken:  3\n",
      "Action taken:  0\n",
      "Action taken:  2\n",
      "Action taken:  1\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  1\n",
      "Action taken:  0\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  2\n",
      "Action taken:  0\n",
      "Action taken:  1\n",
      "Action taken:  0\n",
      "Action taken:  2\n",
      "Action taken:  2\n",
      "Action taken:  0\n",
      "Action taken:  0\n",
      "Action taken:  1\n",
      "Action taken:  0\n",
      "Action taken:  3\n",
      "Action taken:  0\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  1\n",
      "Action taken:  0\n",
      "Action taken:  3\n",
      "Action taken:  0\n",
      "Action taken:  2\n",
      "Action taken:  2\n",
      "Action taken:  0\n",
      "Action taken:  2\n",
      "Action taken:  2\n",
      "Action taken:  3\n",
      "Action taken:  2\n",
      "Action taken:  2\n",
      "Action taken:  0\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  0\n",
      "Action taken:  3\n",
      "Action taken:  0\n",
      "Action taken:  1\n",
      "Action taken:  0\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  2\n",
      "Action taken:  2\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  1\n",
      "Action taken:  1\n",
      "Action taken:  0\n",
      "Action taken:  2\n",
      "Action taken:  1\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  3\n",
      "Action taken:  2\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  0\n",
      "Action taken:  1\n",
      "Action taken:  1\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  2\n",
      "Action taken:  1\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  2\n",
      "Action taken:  3\n",
      "Action taken:  2\n",
      "Action taken:  0\n",
      "Action taken:  2\n",
      "Action taken:  2\n",
      "Action taken:  1\n",
      "Environment is reset\n",
      "Action taken:  0\n",
      "Action taken:  1\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  1\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  0\n",
      "Action taken:  1\n",
      "Action taken:  0\n",
      "Action taken:  1\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  3\n",
      "Action taken:  0\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  0\n",
      "Action taken:  1\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  0\n",
      "Action taken:  1\n",
      "Action taken:  0\n",
      "Action taken:  0\n",
      "Action taken:  0\n",
      "Action taken:  0\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  1\n",
      "Action taken:  0\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  0\n",
      "Action taken:  0\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  0\n",
      "Action taken:  0\n",
      "Action taken:  3\n",
      "Environment is reset\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  0\n",
      "Action taken:  0\n",
      "Action taken:  1\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  2\n",
      "Action taken:  3\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  0\n",
      "Action taken:  0\n",
      "Action taken:  0\n",
      "Action taken:  1\n",
      "Action taken:  1\n",
      "Action taken:  2\n",
      "Action taken:  2\n",
      "Action taken:  1\n",
      "Action taken:  1\n",
      "Action taken:  1\n",
      "Action taken:  0\n",
      "Action taken:  2\n",
      "Action taken:  1\n",
      "Action taken:  1\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  0\n",
      "Action taken:  0\n",
      "Action taken:  1\n",
      "Action taken:  0\n",
      "Action taken:  0\n",
      "Action taken:  2\n",
      "Action taken:  3\n",
      "Action taken:  2\n",
      "Action taken:  2\n",
      "Action taken:  2\n",
      "Action taken:  1\n",
      "Action taken:  3\n",
      "Action taken:  3\n",
      "Action taken:  1\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym \n",
    "\n",
    "# Creating the environment\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"human\")\n",
    "\n",
    "# Resetting the enironment\n",
    "observation, info = env.reset()\n",
    "\n",
    "for _ in range(200):\n",
    "    # Take a random action \n",
    "    action = env.action_space.sample()\n",
    "    print(\"Action taken: \", action)\n",
    "\n",
    "    # Apply this action in the env\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "    if terminated or truncated:\n",
    "        print(\"Environment is reset\")\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08357407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___OBS SPACE___\n",
      "\n",
      "Observation space shape:  (8,)\n",
      "Sample Observation space:  [-2.2554545  -1.4047152  -0.60978454 -5.0573773  -3.5330036   5.566765\n",
      "  0.6627417   0.24428055]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v3\")\n",
    "env.reset()\n",
    "\n",
    "print(\"___OBS SPACE___\\n\")\n",
    "print(\"Observation space shape: \", env.observation_space.shape)\n",
    "print(\"Sample Observation space: \", env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ea98447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " _____ACTION SPACE_____ \n",
      "\n",
      "Action Space Shape 4\n",
      "Action Space Sample 3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
    "print(\"Action Space Shape\", env.action_space.n)\n",
    "print(\"Action Space Sample\", env.action_space.sample())  # Take a random action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9cf46bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_vec_env(\"LunarLander-v3\", n_envs=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e22000",
   "metadata": {},
   "source": [
    "# Setting up StableBaseline 4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7319f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "env = make_vec_env(\"LunarLander-v3\", n_envs=16)\n",
    "\n",
    "# Instantiate the agent\n",
    "model = PPO('MlpPolicy', \n",
    "            env=env, \n",
    "            tensorboard_log=\"./LunarLander-v3_tensorboard/\",\n",
    "            n_steps=1024, \n",
    "            batch_size=64, \n",
    "            n_epochs=4, \n",
    "            gamma=0.999, \n",
    "            gae_lambda=0.98, \n",
    "            ent_coef=0.01,\n",
    "            verbose=1)\n",
    "\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=int(1e6), progress_bar=True)\n",
    "\n",
    "# Save Model to file\n",
    "model.save(\"my_LunarLander-v3_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e4406e",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b3e7719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicco/courses/DeepRlCourse/venv/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "mean_reward=246.93 +/- 22.105188547978273\n"
     ]
    }
   ],
   "source": [
    "eval_env = gym.make(\"LunarLander-v3\")\n",
    "eval_env = Monitor(eval_env)\n",
    "\n",
    "trained_model = PPO.load(\"my_LunarLander-v3_model\", env=eval_env)\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(trained_model, trained_model.get_env(), n_eval_episodes=10, deterministic=True)\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f056e7",
   "metadata": {},
   "source": [
    "# Graphical Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa09195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "Episode is finished\n"
     ]
    }
   ],
   "source": [
    "# Creating the environment\n",
    "env = gym.make(\"LunarLander-v3\", render_mode=\"human\")\n",
    "trained_model = PPO.load(\"my_LunarLander-v3_model\", env=eval_env)\n",
    "\n",
    "# Resetting the enironment\n",
    "observation, info = env.reset()\n",
    "\n",
    "for _ in range(500):\n",
    "    # Take a random action \n",
    "    action, state = trained_model.predict(observation, )\n",
    "    \n",
    "    # Apply this action in the env\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "    if terminated or truncated:\n",
    "        print(\"Episode is finished\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "002972bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ This function will save, evaluate, generate a video of your agent,\n",
      "create a model card and push everything to the hub. It might take up to 1min.\n",
      "This is a work in progress: if you encounter a bug, please open an issue.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicco/courses/DeepRlCourse/venv/lib/python3.12/site-packages/stable_baselines3/common/evaluation.py:70: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving video to /tmp/tmpu93ohzk_/-step-0-to-step-1000.mp4\n",
      "MoviePy - Building video /tmp/tmpu93ohzk_/-step-0-to-step-1000.mp4.\n",
      "MoviePy - Writing video /tmp/tmpu93ohzk_/-step-0-to-step-1000.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready /tmp/tmpu93ohzk_/-step-0-to-step-1000.mp4\n",
      "\u001b[38;5;1m✘ 'DummyVecEnv' object has no attribute 'video_recorder'\u001b[0m\n",
      "\u001b[38;5;1m✘ We are unable to generate a replay of your agent, the package_to_hub\n",
      "process continues\u001b[0m\n",
      "\u001b[38;5;1m✘ Please open an issue at\n",
      "https://github.com/huggingface/huggingface_sb3/issues\u001b[0m\n",
      "\u001b[38;5;4mℹ Pushing repo Pucciland95/ppo-LunarLander-v3 to the Hugging Face\n",
      "Hub\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files (4 / 4): 100%|██████████|  282kB /  282kB,  149kB/s  \n",
      "New Data Upload: 100%|██████████|  109kB /  109kB,  109kB/s  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Your model is pushed to the Hub. You can view your model here:\n",
      "https://huggingface.co/Pucciland95/ppo-LunarLander-v3/tree/main/\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Pucciland95/ppo-LunarLander-v3/commit/c7c678b9c912771347195671c06d64ccfbed56aa', commit_message='Uploaded PPO LunarLander-v3 trained agent', commit_description='', oid='c7c678b9c912771347195671c06d64ccfbed56aa', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Pucciland95/ppo-LunarLander-v3', endpoint='https://huggingface.co', repo_type='model', repo_id='Pucciland95/ppo-LunarLander-v3'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "from huggingface_sb3 import package_to_hub\n",
    "\n",
    "repo_id = \"Pucciland95/ppo-LunarLander-v3\"\n",
    "env_id = \"LunarLander-v3\"\n",
    "\n",
    "eval_env = DummyVecEnv([lambda: gym.make(env_id, render_mode=\"rgb_array\")])\n",
    "\n",
    "model_architecture = \"PPO\"\n",
    "commit_message = \"Uploaded PPO LunarLander-v3 trained agent\"\n",
    "\n",
    "model = PPO.load(\"my_LunarLander-v3_model\", env=eval_env)\n",
    "\n",
    "package_to_hub(model=model, \n",
    "               model_name=\"ChopChopMotherFucker\",\n",
    "               model_architecture=model_architecture,\n",
    "               env_id=env_id,\n",
    "               eval_env=eval_env,\n",
    "               repo_id=repo_id,\n",
    "               commit_message=commit_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfd7c70",
   "metadata": {},
   "source": [
    "# Cloning and Evaluating the Model you just pushed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8979e597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CURRENT SYSTEM INFO ==\n",
      "- OS: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.39 # 1 SMP PREEMPT_DYNAMIC Thu Jun  5 18:30:46 UTC 2025\n",
      "- Python: 3.12.3\n",
      "- Stable-Baselines3: 2.7.0\n",
      "- PyTorch: 2.9.0+cu128\n",
      "- GPU Enabled: False\n",
      "- Numpy: 2.2.6\n",
      "- Cloudpickle: 3.1.1\n",
      "- Gymnasium: 1.2.1\n",
      "\n",
      "== SAVED MODEL SYSTEM INFO ==\n",
      "- OS: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.39 # 1 SMP PREEMPT_DYNAMIC Thu Jun  5 18:30:46 UTC 2025\n",
      "- Python: 3.12.3\n",
      "- Stable-Baselines3: 2.7.0\n",
      "- PyTorch: 2.9.0+cu128\n",
      "- GPU Enabled: False\n",
      "- Numpy: 2.2.6\n",
      "- Cloudpickle: 3.1.1\n",
      "- Gymnasium: 1.2.1\n",
      "\n",
      "mean_reward=268.40 +/- 17.698211256933895\n"
     ]
    }
   ],
   "source": [
    "from huggingface_sb3 import load_from_hub\n",
    "\n",
    "repo_id = \"Pucciland95/ppo-LunarLander-v3\"\n",
    "filename = \"ChopChopMotherFucker.zip\"\n",
    "\n",
    "custom_objects = {\n",
    "            \"learning_rate\": 0.0,\n",
    "            \"lr_schedule\": lambda _: 0.0,\n",
    "            \"clip_range\": lambda _: 0.0,\n",
    "}\n",
    "\n",
    "checkpoint = load_from_hub(repo_id, filename)\n",
    "model = PPO.load(checkpoint, custom_objects=custom_objects, print_system_info=True)\n",
    "\n",
    "eval_env = Monitor(gym.make(\"LunarLander-v3\"))\n",
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
